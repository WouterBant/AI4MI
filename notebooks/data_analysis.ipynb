{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')  # add source directory to path for imports\n",
    "\n",
    "from pathlib import Path\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import class2one_hot\n",
    "from dataset import SliceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\" / Path(\"data\") / \"SEGTHOR\"\n",
    "\n",
    "K = 5  # Number of classes\n",
    "\n",
    "img_transform = transforms.Compose(\n",
    "    [\n",
    "        lambda img: img.convert(\"L\"),  # convert to grayscale\n",
    "        lambda img: np.array(img)[np.newaxis, ...],\n",
    "        lambda nd: nd / 255,  # max <= 1 (range [0, 1])\n",
    "        lambda nd: torch.tensor(nd, dtype=torch.float32),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gt_transform = transforms.Compose(\n",
    "    [\n",
    "        lambda img: np.array(img)[...],\n",
    "        # The idea is that the classes are mapped to {0, 255} for binary cases\n",
    "        # {0, 85, 170, 255} for 4 classes\n",
    "        # {0, 51, 102, 153, 204, 255} for 6 classes\n",
    "        # Very sketchy but that works here and that simplifies visualization\n",
    "        lambda nd: nd / (255 / (K - 1)) if K != 5 else nd / 63,  # max <= 1\n",
    "        lambda nd: torch.tensor(nd, dtype=torch.int64)[\n",
    "            None, ...\n",
    "        ],  # Add one dimension to simulate batch\n",
    "        lambda t: class2one_hot(t, K=K),\n",
    "        itemgetter(0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = SliceDataset(\n",
    "    \"train\",\n",
    "    root_dir,\n",
    "    img_transform=img_transform,\n",
    "    gt_transform=gt_transform,\n",
    "    debug=False,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=1, num_workers=4, shuffle=False\n",
    ")\n",
    "\n",
    "val_set = SliceDataset(\n",
    "    \"val\",\n",
    "    root_dir,\n",
    "    img_transform=img_transform,\n",
    "    gt_transform=gt_transform,\n",
    "    debug=False,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=5, num_workers=4, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check some samples\n",
    "\n",
    "num_samples = 5\n",
    "\n",
    "fig, ax = plt.subplots(2, num_samples, figsize=(15, 6))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if i == num_samples:\n",
    "        break\n",
    "\n",
    "    img = batch[\"images\"]\n",
    "    gt = batch[\"gts\"]\n",
    "\n",
    "    color_map = plt.get_cmap(\"viridis\", K)\n",
    "    gt_colored = color_map(gt[0].argmax(dim=0).cpu().numpy())\n",
    "\n",
    "    ax[0, i].imshow(img[0, 0], cmap=\"gray\")\n",
    "    ax[1, i].imshow(gt_colored)\n",
    "\n",
    "    ax[0, i].axis('off')\n",
    "    ax[1, i].axis('off')\n",
    "\n",
    "legend_elements = [\n",
    "    plt.Rectangle((0, 0), 1, 1, color=color_map(i)) for i in range(K)\n",
    "]\n",
    "fig.legend(\n",
    "    legend_elements, \n",
    "    [\"Background\", \"Esophagus\", \"Heart\", \"Trachea\", \"Aorta\"], \n",
    "    loc=\"lower center\", \n",
    "    ncol=K\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of ground truth images that are completely background\n",
    "\n",
    "def print_stats(data_loader):\n",
    "    n_background = total = 0\n",
    "    n_esophagus = n_heart = n_trachea = n_aorta = 0\n",
    "\n",
    "    for i, batch in tqdm(enumerate(data_loader)):\n",
    "        gt = batch[\"gts\"]\n",
    "\n",
    "        mask = gt[0].argmax(dim=0)\n",
    "        if mask.sum() == 0:\n",
    "            n_background += 1\n",
    "            total += 1\n",
    "            continue\n",
    "\n",
    "        if mask.eq(1).sum() > 0:\n",
    "            n_esophagus += 1\n",
    "        if mask.eq(2).sum() > 0:\n",
    "            n_heart += 1\n",
    "        if mask.eq(3).sum() > 0:\n",
    "            n_trachea += 1\n",
    "        if mask.eq(4).sum() > 0:\n",
    "            n_aorta += 1\n",
    "        total += 1\n",
    "\n",
    "    print(f\"\\nTotal number of ground truth images: {total}\\n\")\n",
    "    print(f\"Number of ground truth images that are completely background: {n_background}\")\n",
    "    print(f\"Percentage: {n_background / total * 100:.2f}%\\n\")\n",
    "    print(f\"Number of esophagus images: {n_esophagus}\")\n",
    "    print(f\"Percentage: {n_esophagus / total * 100:.2f}%\\n\")\n",
    "    print(f\"Number of heart images: {n_heart}\")\n",
    "    print(f\"Percentage: {n_heart / total * 100:.2f}%\\n\")\n",
    "    print(f\"Number of trachea images: {n_trachea}\")\n",
    "    print(f\"Percentage: {n_trachea / total * 100:.2f}%\\n\")\n",
    "    print(f\"Number of aorta images: {n_aorta}\")\n",
    "    print(f\"Percentage: {n_aorta / total * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set:\\n\")\n",
    "print_stats(train_loader)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Validation set:\\n\")\n",
    "print_stats(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check some non-background samples\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=1, num_workers=4, shuffle=True\n",
    ")\n",
    "\n",
    "num_samples = 5\n",
    "\n",
    "fig, ax = plt.subplots(3, num_samples, figsize=(15, 9))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "current_sample = 0\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if current_sample == num_samples:\n",
    "        break\n",
    "\n",
    "    img = batch[\"images\"]\n",
    "    gt = batch[\"gts\"]\n",
    "\n",
    "    if gt[0].argmax(dim=0).sum() == 0:\n",
    "        continue\n",
    "\n",
    "    color_map = plt.get_cmap(\"viridis\", K)\n",
    "    gt_colored = color_map(gt[0].argmax(dim=0).cpu().numpy())\n",
    "\n",
    "    ax[0, current_sample].imshow(img[0, 0], cmap=\"gray\")\n",
    "    ax[1, current_sample].imshow(gt_colored)\n",
    "\n",
    "    ax[0, current_sample].axis('off')\n",
    "    ax[1, current_sample].axis('off')\n",
    "\n",
    "    # Overlay the colored ground truth on the original image\n",
    "    ax[2, current_sample].imshow(img[0, 0], cmap=\"gray\")\n",
    "    ax[2, current_sample].imshow(gt_colored, alpha=0.5)\n",
    "\n",
    "    ax[0, current_sample].axis('off')\n",
    "    ax[1, current_sample].axis('off')\n",
    "    ax[2, current_sample].axis('off')\n",
    "\n",
    "    current_sample += 1\n",
    "\n",
    "legend_elements = [\n",
    "    plt.Rectangle((0, 0), 1, 1, color=color_map(i)) for i in range(K)\n",
    "]\n",
    "fig.legend(\n",
    "    legend_elements, \n",
    "    [\"Background\", \"Esophagus\", \"Heart\", \"Trachea\", \"Aorta\"], \n",
    "    loc=\"lower center\", \n",
    "    ncol=K\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=1, num_workers=4, shuffle=False\n",
    ")\n",
    "\n",
    "num_samples = int(len(train_loader)*0.2)\n",
    "imgs = []\n",
    "gts = []\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if i == num_samples:\n",
    "        break\n",
    "\n",
    "    img = batch[\"images\"]\n",
    "    gt = batch[\"gts\"]\n",
    "\n",
    "    imgs.append(img)\n",
    "    gts.append(gt)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "def update_frame(i):\n",
    "    ax.clear()\n",
    "    img = imgs[i]\n",
    "    gt = gts[i]\n",
    "\n",
    "    color_map = plt.get_cmap(\"viridis\", K)\n",
    "    gt_colored = color_map(gt[0].argmax(dim=0).cpu().numpy())\n",
    "\n",
    "    # Overlay the colored ground truth on the original image without background\n",
    "    ax.imshow(img[0, 0], cmap=\"gray\")\n",
    "    ax.imshow(gt_colored, alpha=0.5)\n",
    "    ax.axis('off')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update_frame, frames=num_samples, repeat=False)\n",
    "\n",
    "# Save the animation as a video file\n",
    "ani.save('overlapping_images.mp4', writer='ffmpeg', fps=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
